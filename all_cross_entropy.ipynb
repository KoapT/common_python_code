{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4868, -0.6038, -0.5581,  0.6675, -0.1974],\n",
      "        [ 1.9428, -1.4017, -0.7626,  0.6312, -0.8991],\n",
      "        [-0.5578,  0.6907,  0.2225, -0.6662,  0.6846]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "pred = torch.randn(3, 5, requires_grad=True)        # 模拟预测结果，3个目标，共有5类，\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟GT。 其中target1是target2的onehot形式。\n",
    "# target1的形式，可以表示非互斥类别目标（即1目标可是多类别），\n",
    "# 但是target2的形式表示的目标只能有一个类别。\n",
    "target1 = torch.tensor([[1., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 1., 0.],\n",
    "                        [0., 1., 0., 0., 0.]])\n",
    "target2 = torch.tensor([0, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3807, 0.3535, 0.3640, 0.6609, 0.4508],\n",
      "        [0.8747, 0.1975, 0.3181, 0.6528, 0.2892],\n",
      "        [0.3641, 0.6661, 0.5554, 0.3393, 0.6648]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.1365, 0.1214, 0.1271, 0.4328, 0.1823],\n",
      "        [0.6994, 0.0247, 0.0468, 0.1884, 0.0408],\n",
      "        [0.0907, 0.3160, 0.1979, 0.0814, 0.3141]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 分别计算 pred的 sigmoid和softmax\n",
    "sigmoid_pred = torch.sigmoid(pred)\n",
    "softmax_pred = torch.softmax(pred,1)\n",
    "print(sigmoid_pred)\n",
    "print(softmax_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3807, 0.3535, 0.3640, 0.6609, 0.4508],\n",
      "        [0.8747, 0.1975, 0.3181, 0.6528, 0.2892],\n",
      "        [0.3641, 0.6661, 0.5554, 0.3393, 0.6648]], grad_fn=<MulBackward0>)\n",
      "tensor([[0.1365, 0.1214, 0.1271, 0.4328, 0.1823],\n",
      "        [0.6994, 0.0247, 0.0468, 0.1884, 0.0408],\n",
      "        [0.0907, 0.3160, 0.1979, 0.0814, 0.3141]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 手写一遍公式，验证\n",
    "import numpy as np\n",
    "_sigmoid_pred = 1/(1+np.e**(-pred))                                # sigmoid公式\n",
    "_softmax_pred = np.e**pred/(np.e**pred).sum(1,keepdim=True)        # softmax公式\n",
    "print(_sigmoid_pred)\n",
    "print(_softmax_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9659, 0.4361, 0.4525, 1.0816, 0.5993],\n",
      "        [2.0767, 0.2201, 0.3829, 0.4265, 0.3414],\n",
      "        [0.4526, 0.4063, 0.8105, 0.4145, 1.0930]],\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[0.9659, 0.4361, 0.4525, 1.0816, 0.5993],\n",
      "        [2.0767, 0.2201, 0.3829, 0.4265, 0.3414],\n",
      "        [0.4526, 0.4063, 0.8105, 0.4145, 1.0930]],\n",
      "       grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor([1.9917, 1.6691, 1.1520], grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 用torch的函数计算3个CEloss\n",
    "loss1 = F.binary_cross_entropy_with_logits(pred, target1, reduction='none')\n",
    "loss2 = F.binary_cross_entropy(sigmoid_pred, target1,reduction='none')\n",
    "loss3 = F.cross_entropy(pred, target2, reduction='none')\n",
    "print(loss1)\n",
    "print(loss2)\n",
    "print(loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9659, 0.4361, 0.4525, 1.0816, 0.5993],\n",
      "        [2.0767, 0.2201, 0.3829, 0.4265, 0.3414],\n",
      "        [0.4526, 0.4063, 0.8105, 0.4145, 1.0930]], grad_fn=<SubBackward0>)\n",
      "tensor([1.9917, 1.6691, 1.1520], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 手写celoss验证\n",
    "_loss1=-target1*torch.log(sigmoid_pred)-(1-target1)*torch.log(1-sigmoid_pred)\n",
    "_loss3=torch.sum(-target1*torch.log(softmax_pred),1)\n",
    "print(_loss1)\n",
    "print(_loss3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae23bd67569ab42c5a20ae6a6c125e43da916208860e6403b9c9d404e780d766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
